{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3187418d",
   "metadata": {},
   "source": [
    "# Data cleaning, wrangling and merging of databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6086f",
   "metadata": {},
   "source": [
    "## Bike rental starter kit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c4071",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4254710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d61b36",
   "metadata": {},
   "source": [
    "### Concatenation of bike rental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6fd3f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('JC-2016**-citibike-tripdata.csv')\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    df_list.append(data)\n",
    "\n",
    "rental_data = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671834b",
   "metadata": {},
   "source": [
    "### Examination of bike rental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e2df8128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trip Duration           Start Time            Stop Time  Start Station ID  \\\n",
      "0            362  2016-01-01 00:02:52  2016-01-01 00:08:54              3186   \n",
      "1            200  2016-01-01 00:18:22  2016-01-01 00:21:42              3186   \n",
      "2            202  2016-01-01 00:18:25  2016-01-01 00:21:47              3186   \n",
      "3            248  2016-01-01 00:23:13  2016-01-01 00:27:21              3209   \n",
      "4            903  2016-01-01 01:03:20  2016-01-01 01:18:24              3195   \n",
      "5            883  2016-01-01 01:03:28  2016-01-01 01:18:11              3195   \n",
      "6            445  2016-01-01 01:07:45  2016-01-01 01:15:11              3186   \n",
      "7            192  2016-01-01 01:18:51  2016-01-01 01:22:03              3211   \n",
      "8            409  2016-01-01 01:23:44  2016-01-01 01:30:34              3187   \n",
      "9            285  2016-01-01 01:25:12  2016-01-01 01:29:57              3187   \n",
      "\n",
      "  Start Station Name  Start Station Latitude  Start Station Longitude  \\\n",
      "0      Grove St PATH               40.719586               -74.043117   \n",
      "1      Grove St PATH               40.719586               -74.043117   \n",
      "2      Grove St PATH               40.719586               -74.043117   \n",
      "3       Brunswick St               40.724176               -74.050656   \n",
      "4            Sip Ave               40.730743               -74.063784   \n",
      "5            Sip Ave               40.730743               -74.063784   \n",
      "6      Grove St PATH               40.719586               -74.043117   \n",
      "7         Newark Ave               40.721525               -74.046305   \n",
      "8          Warren St               40.721124               -74.038051   \n",
      "9          Warren St               40.721124               -74.038051   \n",
      "\n",
      "   End Station ID  End Station Name  End Station Latitude  \\\n",
      "0            3209      Brunswick St             40.724176   \n",
      "1            3213    Van Vorst Park             40.718489   \n",
      "2            3213    Van Vorst Park             40.718489   \n",
      "3            3203     Hamilton Park             40.727596   \n",
      "4            3210    Pershing Field             40.742677   \n",
      "5            3210    Pershing Field             40.742677   \n",
      "6            3203     Hamilton Park             40.727596   \n",
      "7            3203     Hamilton Park             40.727596   \n",
      "8            3214  Essex Light Rail             40.712774   \n",
      "9            3214  Essex Light Rail             40.712774   \n",
      "\n",
      "   End Station Longitude  Bike ID   User Type  Birth Year  Gender  \n",
      "0             -74.050656    24647  Subscriber      1964.0       2  \n",
      "1             -74.047727    24605  Subscriber      1962.0       1  \n",
      "2             -74.047727    24689  Subscriber      1962.0       2  \n",
      "3             -74.044247    24693  Subscriber      1984.0       1  \n",
      "4             -74.051789    24573    Customer         NaN       0  \n",
      "5             -74.051789    24442    Customer         NaN       0  \n",
      "6             -74.044247    24510  Subscriber      1988.0       2  \n",
      "7             -74.044247    24625  Subscriber      1980.0       1  \n",
      "8             -74.036486    24429  Subscriber      1990.0       1  \n",
      "9             -74.036486    24407  Subscriber      1988.0       2  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 247584 entries, 0 to 15113\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   Trip Duration            247584 non-null  int64  \n",
      " 1   Start Time               247584 non-null  object \n",
      " 2   Stop Time                247584 non-null  object \n",
      " 3   Start Station ID         247584 non-null  int64  \n",
      " 4   Start Station Name       247584 non-null  object \n",
      " 5   Start Station Latitude   247584 non-null  float64\n",
      " 6   Start Station Longitude  247584 non-null  float64\n",
      " 7   End Station ID           247584 non-null  int64  \n",
      " 8   End Station Name         247584 non-null  object \n",
      " 9   End Station Latitude     247584 non-null  float64\n",
      " 10  End Station Longitude    247584 non-null  float64\n",
      " 11  Bike ID                  247584 non-null  int64  \n",
      " 12  User Type                247204 non-null  object \n",
      " 13  Birth Year               228585 non-null  float64\n",
      " 14  Gender                   247584 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 30.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rental_data.head(10))\n",
    "print(rental_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80dfec",
   "metadata": {},
   "source": [
    "* The column titles dont follow conventional rules\n",
    "* There is some data missing from User type (380 entries 0.15%) \n",
    "* There is some data missing from Birth year (18999 entries missing, 7.7 %) \n",
    "* Although there is no missing data in the Gender column, one entry is 0 which represents unknown and is therefore effectively missing data \n",
    "* Start and stop times should be dates (changed below) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1313954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_data.columns = [x.replace(' ','_') for x in rental_data.columns]\n",
    "rental_data.columns = [x.lower() for x in rental_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9ef2a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_data['start_time'] = rental_data['start_time'].astype('datetime64[ns]')\n",
    "rental_data['stop_time'] = rental_data['stop_time'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "251f1065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.475840e+05</td>\n",
       "      <td>247584</td>\n",
       "      <td>247584</td>\n",
       "      <td>247584.000000</td>\n",
       "      <td>247584.000000</td>\n",
       "      <td>247584.000000</td>\n",
       "      <td>247584.000000</td>\n",
       "      <td>247584.000000</td>\n",
       "      <td>247584.000000</td>\n",
       "      <td>247584.000000</td>\n",
       "      <td>228585.000000</td>\n",
       "      <td>247584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.856305e+02</td>\n",
       "      <td>2016-07-29 05:55:07.541335040</td>\n",
       "      <td>2016-07-29 06:09:53.671073536</td>\n",
       "      <td>3207.065206</td>\n",
       "      <td>40.723121</td>\n",
       "      <td>-74.046438</td>\n",
       "      <td>3203.572553</td>\n",
       "      <td>40.722594</td>\n",
       "      <td>-74.045855</td>\n",
       "      <td>24935.260481</td>\n",
       "      <td>1979.335276</td>\n",
       "      <td>1.123534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.100000e+01</td>\n",
       "      <td>2016-01-01 00:02:52</td>\n",
       "      <td>2016-01-01 00:08:54</td>\n",
       "      <td>3183.000000</td>\n",
       "      <td>40.692640</td>\n",
       "      <td>-74.096937</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>40.692216</td>\n",
       "      <td>-74.096937</td>\n",
       "      <td>14552.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.480000e+02</td>\n",
       "      <td>2016-05-27 07:46:06</td>\n",
       "      <td>2016-05-27 07:54:40.249999872</td>\n",
       "      <td>3186.000000</td>\n",
       "      <td>40.717732</td>\n",
       "      <td>-74.050656</td>\n",
       "      <td>3186.000000</td>\n",
       "      <td>40.716540</td>\n",
       "      <td>-74.050444</td>\n",
       "      <td>24491.000000</td>\n",
       "      <td>1974.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.900000e+02</td>\n",
       "      <td>2016-08-10 09:23:50</td>\n",
       "      <td>2016-08-10 09:34:32.500000</td>\n",
       "      <td>3201.000000</td>\n",
       "      <td>40.721525</td>\n",
       "      <td>-74.044247</td>\n",
       "      <td>3199.000000</td>\n",
       "      <td>40.721124</td>\n",
       "      <td>-74.043117</td>\n",
       "      <td>24609.000000</td>\n",
       "      <td>1981.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.660000e+02</td>\n",
       "      <td>2016-10-05 17:25:05.500000</td>\n",
       "      <td>2016-10-05 17:33:00.750000128</td>\n",
       "      <td>3211.000000</td>\n",
       "      <td>40.727596</td>\n",
       "      <td>-74.038051</td>\n",
       "      <td>3211.000000</td>\n",
       "      <td>40.727224</td>\n",
       "      <td>-74.036486</td>\n",
       "      <td>24719.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.632981e+07</td>\n",
       "      <td>2016-12-31 23:44:50</td>\n",
       "      <td>2017-01-18 14:26:46</td>\n",
       "      <td>3426.000000</td>\n",
       "      <td>40.752559</td>\n",
       "      <td>-74.032108</td>\n",
       "      <td>3426.000000</td>\n",
       "      <td>40.801343</td>\n",
       "      <td>-73.957390</td>\n",
       "      <td>27274.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.593798e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.955103</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.011211</td>\n",
       "      <td>61.579494</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.011283</td>\n",
       "      <td>748.469712</td>\n",
       "      <td>9.596809</td>\n",
       "      <td>0.518687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trip_duration                     start_time  \\\n",
       "count   2.475840e+05                         247584   \n",
       "mean    8.856305e+02  2016-07-29 05:55:07.541335040   \n",
       "min     6.100000e+01            2016-01-01 00:02:52   \n",
       "25%     2.480000e+02            2016-05-27 07:46:06   \n",
       "50%     3.900000e+02            2016-08-10 09:23:50   \n",
       "75%     6.660000e+02     2016-10-05 17:25:05.500000   \n",
       "max     1.632981e+07            2016-12-31 23:44:50   \n",
       "std     3.593798e+04                            NaN   \n",
       "\n",
       "                           stop_time  start_station_id  \\\n",
       "count                         247584     247584.000000   \n",
       "mean   2016-07-29 06:09:53.671073536       3207.065206   \n",
       "min              2016-01-01 00:08:54       3183.000000   \n",
       "25%    2016-05-27 07:54:40.249999872       3186.000000   \n",
       "50%       2016-08-10 09:34:32.500000       3201.000000   \n",
       "75%    2016-10-05 17:33:00.750000128       3211.000000   \n",
       "max              2017-01-18 14:26:46       3426.000000   \n",
       "std                              NaN         26.955103   \n",
       "\n",
       "       start_station_latitude  start_station_longitude  end_station_id  \\\n",
       "count           247584.000000            247584.000000   247584.000000   \n",
       "mean                40.723121               -74.046438     3203.572553   \n",
       "min                 40.692640               -74.096937      147.000000   \n",
       "25%                 40.717732               -74.050656     3186.000000   \n",
       "50%                 40.721525               -74.044247     3199.000000   \n",
       "75%                 40.727596               -74.038051     3211.000000   \n",
       "max                 40.752559               -74.032108     3426.000000   \n",
       "std                  0.008199                 0.011211       61.579494   \n",
       "\n",
       "       end_station_latitude  end_station_longitude        bike_id  \\\n",
       "count         247584.000000          247584.000000  247584.000000   \n",
       "mean              40.722594             -74.045855   24935.260481   \n",
       "min               40.692216             -74.096937   14552.000000   \n",
       "25%               40.716540             -74.050444   24491.000000   \n",
       "50%               40.721124             -74.043117   24609.000000   \n",
       "75%               40.727224             -74.036486   24719.000000   \n",
       "max               40.801343             -73.957390   27274.000000   \n",
       "std                0.007958               0.011283     748.469712   \n",
       "\n",
       "          birth_year         gender  \n",
       "count  228585.000000  247584.000000  \n",
       "mean     1979.335276       1.123534  \n",
       "min      1900.000000       0.000000  \n",
       "25%      1974.000000       1.000000  \n",
       "50%      1981.000000       1.000000  \n",
       "75%      1986.000000       1.000000  \n",
       "max      2000.000000       2.000000  \n",
       "std         9.596809       0.518687  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8513e",
   "metadata": {},
   "source": [
    "* The maximum trip duration looks excessive at 189 days. In addition, the website states that bikes must be returned within 24 hours (86400 seconds)\n",
    "* One of the riders appears to be 116 years old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada8b07",
   "metadata": {},
   "source": [
    "### Further investigation into trip durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f59c5ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 93 entries, 307 to 14897\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   trip_duration            93 non-null     int64         \n",
      " 1   start_time               93 non-null     datetime64[ns]\n",
      " 2   stop_time                93 non-null     datetime64[ns]\n",
      " 3   start_station_id         93 non-null     int64         \n",
      " 4   start_station_name       93 non-null     object        \n",
      " 5   start_station_latitude   93 non-null     float64       \n",
      " 6   start_station_longitude  93 non-null     float64       \n",
      " 7   end_station_id           93 non-null     int64         \n",
      " 8   end_station_name         93 non-null     object        \n",
      " 9   end_station_latitude     93 non-null     float64       \n",
      " 10  end_station_longitude    93 non-null     float64       \n",
      " 11  bike_id                  93 non-null     int64         \n",
      " 12  user_type                93 non-null     object        \n",
      " 13  birth_year               42 non-null     float64       \n",
      " 14  gender                   93 non-null     int64         \n",
      "dtypes: datetime64[ns](2), float64(5), int64(5), object(3)\n",
      "memory usage: 11.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "long_durations = rental_data[rental_data['trip_duration'] > 86400]\n",
    "\n",
    "print(long_durations.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6fb46e",
   "metadata": {},
   "source": [
    "* There are 93 entries that exceed the 24 hour limit. As these could be caused by bad docking it is important that they are kept within the results. A new column will therefore be added to state if the time limit has been exceeded. \n",
    "* In addition, a new column was added to give the duration in  minutes which is more useful than seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7baa4974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_duration          start_time           stop_time  start_station_id  \\\n",
      "0            362 2016-01-01 00:02:52 2016-01-01 00:08:54              3186   \n",
      "1            200 2016-01-01 00:18:22 2016-01-01 00:21:42              3186   \n",
      "2            202 2016-01-01 00:18:25 2016-01-01 00:21:47              3186   \n",
      "3            248 2016-01-01 00:23:13 2016-01-01 00:27:21              3209   \n",
      "4            903 2016-01-01 01:03:20 2016-01-01 01:18:24              3195   \n",
      "\n",
      "  start_station_name  start_station_latitude  start_station_longitude  \\\n",
      "0      Grove St PATH               40.719586               -74.043117   \n",
      "1      Grove St PATH               40.719586               -74.043117   \n",
      "2      Grove St PATH               40.719586               -74.043117   \n",
      "3       Brunswick St               40.724176               -74.050656   \n",
      "4            Sip Ave               40.730743               -74.063784   \n",
      "\n",
      "   end_station_id end_station_name  end_station_latitude  \\\n",
      "0            3209     Brunswick St             40.724176   \n",
      "1            3213   Van Vorst Park             40.718489   \n",
      "2            3213   Van Vorst Park             40.718489   \n",
      "3            3203    Hamilton Park             40.727596   \n",
      "4            3210   Pershing Field             40.742677   \n",
      "\n",
      "   end_station_longitude  bike_id   user_type  birth_year  gender  \\\n",
      "0             -74.050656    24647  Subscriber      1964.0       2   \n",
      "1             -74.047727    24605  Subscriber      1962.0       1   \n",
      "2             -74.047727    24689  Subscriber      1962.0       2   \n",
      "3             -74.044247    24693  Subscriber      1984.0       1   \n",
      "4             -74.051789    24573    Customer         NaN       0   \n",
      "\n",
      "   duration_exceeded  duration_minutes  \n",
      "0              False              6.03  \n",
      "1              False              3.33  \n",
      "2              False              3.37  \n",
      "3              False              4.13  \n",
      "4              False             15.05  \n"
     ]
    }
   ],
   "source": [
    "rental_data['duration_exceeded'] = rental_data['trip_duration'].apply(lambda x: 1 if x > 86400 else 0).astype(bool)\n",
    "rental_data['duration_minutes'] = round(rental_data['trip_duration'] / 60, 2)\n",
    "\n",
    "\n",
    "print(rental_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00cc6a",
   "metadata": {},
   "source": [
    "### Further investigation into Birth Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f6dd3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       trip_duration                     start_time  \\\n",
      "count   2.475720e+05                         247572   \n",
      "mean    8.856405e+02  2016-07-29 05:57:31.958601984   \n",
      "min     6.100000e+01            2016-01-01 00:02:52   \n",
      "25%     2.480000e+02     2016-05-27 07:46:11.500000   \n",
      "50%     3.900000e+02            2016-08-10 09:25:31   \n",
      "75%     6.660000e+02  2016-10-05 17:25:37.750000128   \n",
      "max     1.632981e+07            2016-12-31 23:44:50   \n",
      "std     3.593885e+04                            NaN   \n",
      "\n",
      "                           stop_time  start_station_id  \\\n",
      "count                         247572     247572.000000   \n",
      "mean   2016-07-29 06:12:18.098290432       3207.065318   \n",
      "min              2016-01-01 00:08:54       3183.000000   \n",
      "25%              2016-05-27 07:56:36       3186.000000   \n",
      "50%       2016-08-10 09:36:25.500000       3201.000000   \n",
      "75%              2016-10-05 17:34:12       3211.000000   \n",
      "max              2017-01-18 14:26:46       3426.000000   \n",
      "std                              NaN         26.955263   \n",
      "\n",
      "       start_station_latitude  start_station_longitude  end_station_id  \\\n",
      "count           247572.000000            247572.000000   247572.000000   \n",
      "mean                40.723121               -74.046438     3203.572516   \n",
      "min                 40.692640               -74.096937      147.000000   \n",
      "25%                 40.717732               -74.050656     3186.000000   \n",
      "50%                 40.721525               -74.044247     3199.000000   \n",
      "75%                 40.727596               -74.038051     3211.000000   \n",
      "max                 40.752559               -74.032108     3426.000000   \n",
      "std                  0.008199                 0.011211       61.580654   \n",
      "\n",
      "       end_station_latitude  end_station_longitude        bike_id  \\\n",
      "count         247572.000000          247572.000000  247572.000000   \n",
      "mean              40.722594             -74.045855   24935.264279   \n",
      "min               40.692216             -74.096937   14552.000000   \n",
      "25%               40.716540             -74.050444   24491.000000   \n",
      "50%               40.721124             -74.043117   24609.000000   \n",
      "75%               40.727224             -74.036486   24719.000000   \n",
      "max               40.801343             -73.957390   27274.000000   \n",
      "std                0.007958               0.011283     748.475924   \n",
      "\n",
      "          birth_year         gender  duration_minutes            age  \n",
      "count  228573.000000  247572.000000     247572.000000  228573.000000  \n",
      "mean     1979.335451       1.123528         14.760669      36.664549  \n",
      "min      1934.000000       0.000000          1.020000      16.000000  \n",
      "25%      1974.000000       1.000000          4.130000      30.000000  \n",
      "50%      1981.000000       1.000000          6.500000      35.000000  \n",
      "75%      1986.000000       1.000000         11.100000      42.000000  \n",
      "max      2000.000000       2.000000     272163.470000      82.000000  \n",
      "std         9.595412       0.518690        598.980795       9.595412  \n"
     ]
    }
   ],
   "source": [
    "rental_data['birth_year'].sort_values()\n",
    "rental_data.drop([4417], inplace=True)\n",
    "rental_data['age'] = 2016 - rental_data['birth_year']\n",
    "print(rental_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e0cfc",
   "metadata": {},
   "source": [
    "* The row containing the rider who was 116 years old has been removed.\n",
    "* An additional column has been added to display the age of each rider which is more useful than their data of birth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30180c97",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67447e0b",
   "metadata": {},
   "source": [
    "* There are two columns (Birth Year and User Type) containing significant amounts of missing data and the gender column also contains an unknown option, 0, which is effectively also missing data.\n",
    "* Firstly the missing user type will be investigated \n",
    "* When the first 10 rows of data are inspected this missing data and gender == 0 always came from the customer selection in User Type\n",
    "* The data will be filtered for each User Type and the missing values recounted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "052fd5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subscriber' 'Customer' nan]\n",
      "gender\n",
      "1    262\n",
      "2    118\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 380 entries, 9538 to 14273\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   trip_duration            380 non-null    int64         \n",
      " 1   start_time               380 non-null    datetime64[ns]\n",
      " 2   stop_time                380 non-null    datetime64[ns]\n",
      " 3   start_station_id         380 non-null    int64         \n",
      " 4   start_station_name       380 non-null    object        \n",
      " 5   start_station_latitude   380 non-null    float64       \n",
      " 6   start_station_longitude  380 non-null    float64       \n",
      " 7   end_station_id           380 non-null    int64         \n",
      " 8   end_station_name         380 non-null    object        \n",
      " 9   end_station_latitude     380 non-null    float64       \n",
      " 10  end_station_longitude    380 non-null    float64       \n",
      " 11  bike_id                  380 non-null    int64         \n",
      " 12  user_type                0 non-null      object        \n",
      " 13  birth_year               380 non-null    float64       \n",
      " 14  gender                   380 non-null    int64         \n",
      " 15  duration_exceeded        380 non-null    bool          \n",
      " 16  duration_minutes         380 non-null    float64       \n",
      " 17  age                      380 non-null    float64       \n",
      "dtypes: bool(1), datetime64[ns](2), float64(7), int64(5), object(3)\n",
      "memory usage: 53.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rental_data['user_type'].unique())\n",
    "\n",
    "missing_user_type = rental_data[rental_data[['user_type']].isnull().any(axis=1)]\n",
    "\n",
    "print(missing_user_type['gender'].value_counts())\n",
    "print(missing_user_type.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc373352",
   "metadata": {},
   "source": [
    "* The missing user type rows do not have missing Birth Years or genders = 0. Therefore this data is still useful. The NaN results will therefore be changed to unknown user types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "513cd291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 247572 entries, 0 to 15113\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   trip_duration            247572 non-null  int64         \n",
      " 1   start_time               247572 non-null  datetime64[ns]\n",
      " 2   stop_time                247572 non-null  datetime64[ns]\n",
      " 3   start_station_id         247572 non-null  int64         \n",
      " 4   start_station_name       247572 non-null  object        \n",
      " 5   start_station_latitude   247572 non-null  float64       \n",
      " 6   start_station_longitude  247572 non-null  float64       \n",
      " 7   end_station_id           247572 non-null  int64         \n",
      " 8   end_station_name         247572 non-null  object        \n",
      " 9   end_station_latitude     247572 non-null  float64       \n",
      " 10  end_station_longitude    247572 non-null  float64       \n",
      " 11  bike_id                  247572 non-null  int64         \n",
      " 12  user_type                247572 non-null  object        \n",
      " 13  birth_year               228573 non-null  float64       \n",
      " 14  gender                   247572 non-null  int64         \n",
      " 15  duration_exceeded        247572 non-null  bool          \n",
      " 16  duration_minutes         247572 non-null  float64       \n",
      " 17  age                      228573 non-null  float64       \n",
      "dtypes: bool(1), datetime64[ns](2), float64(7), int64(5), object(3)\n",
      "memory usage: 34.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rental_data = rental_data.fillna(value={'user_type': 'Unknown'})\n",
    "print(rental_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0acd6792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 231671 entries, 0 to 15113\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   trip_duration            231671 non-null  int64         \n",
      " 1   start_time               231671 non-null  datetime64[ns]\n",
      " 2   stop_time                231671 non-null  datetime64[ns]\n",
      " 3   start_station_id         231671 non-null  int64         \n",
      " 4   start_station_name       231671 non-null  object        \n",
      " 5   start_station_latitude   231671 non-null  float64       \n",
      " 6   start_station_longitude  231671 non-null  float64       \n",
      " 7   end_station_id           231671 non-null  int64         \n",
      " 8   end_station_name         231671 non-null  object        \n",
      " 9   end_station_latitude     231671 non-null  float64       \n",
      " 10  end_station_longitude    231671 non-null  float64       \n",
      " 11  bike_id                  231671 non-null  int64         \n",
      " 12  user_type                231671 non-null  object        \n",
      " 13  birth_year               228142 non-null  float64       \n",
      " 14  gender                   231671 non-null  int64         \n",
      " 15  duration_exceeded        231671 non-null  bool          \n",
      " 16  duration_minutes         231671 non-null  float64       \n",
      " 17  age                      228142 non-null  float64       \n",
      "dtypes: bool(1), datetime64[ns](2), float64(7), int64(5), object(3)\n",
      "memory usage: 32.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15521 entries, 4 to 15110\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   trip_duration            15521 non-null  int64         \n",
      " 1   start_time               15521 non-null  datetime64[ns]\n",
      " 2   stop_time                15521 non-null  datetime64[ns]\n",
      " 3   start_station_id         15521 non-null  int64         \n",
      " 4   start_station_name       15521 non-null  object        \n",
      " 5   start_station_latitude   15521 non-null  float64       \n",
      " 6   start_station_longitude  15521 non-null  float64       \n",
      " 7   end_station_id           15521 non-null  int64         \n",
      " 8   end_station_name         15521 non-null  object        \n",
      " 9   end_station_latitude     15521 non-null  float64       \n",
      " 10  end_station_longitude    15521 non-null  float64       \n",
      " 11  bike_id                  15521 non-null  int64         \n",
      " 12  user_type                15521 non-null  object        \n",
      " 13  birth_year               51 non-null     float64       \n",
      " 14  gender                   15521 non-null  int64         \n",
      " 15  duration_exceeded        15521 non-null  bool          \n",
      " 16  duration_minutes         15521 non-null  float64       \n",
      " 17  age                      51 non-null     float64       \n",
      "dtypes: bool(1), datetime64[ns](2), float64(7), int64(5), object(3)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "Subscribed: gender\n",
      "1    176890\n",
      "2     50350\n",
      "0      4431\n",
      "Name: count, dtype: int64\n",
      "Customer: gender\n",
      "0    15470\n",
      "1       36\n",
      "2       15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_subscriber = rental_data[rental_data['user_type'] == 'Subscriber']\n",
    "df_customer = rental_data[rental_data['user_type'] == 'Customer']\n",
    "\n",
    "print(df_subscriber.info())\n",
    "print(df_customer.info())\n",
    "\n",
    "print('Subscribed:', df_subscriber['gender'].value_counts())\n",
    "print('Customer:', df_customer['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c861963a",
   "metadata": {},
   "source": [
    "* Missing Birth Year:\\\n",
    "Subscriber: 1.5 %\\\n",
    "Customer: 99.7 %\n",
    "\n",
    "* Gender = 0:\\\n",
    "Subscriber: 1.9 %\\\n",
    "Customer: 99.7 %\n",
    "\n",
    "* The majority of the missing data and gender=0 is from the customer user type. This cant be deleted as it covers the majority of the customer entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0f82e",
   "metadata": {},
   "source": [
    "### Creating date related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7a535cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_duration          start_time           stop_time  start_station_id  \\\n",
      "0            362 2016-01-01 00:02:52 2016-01-01 00:08:54              3186   \n",
      "1            200 2016-01-01 00:18:22 2016-01-01 00:21:42              3186   \n",
      "2            202 2016-01-01 00:18:25 2016-01-01 00:21:47              3186   \n",
      "3            248 2016-01-01 00:23:13 2016-01-01 00:27:21              3209   \n",
      "4            903 2016-01-01 01:03:20 2016-01-01 01:18:24              3195   \n",
      "\n",
      "  start_station_name  start_station_latitude  start_station_longitude  \\\n",
      "0      Grove St PATH               40.719586               -74.043117   \n",
      "1      Grove St PATH               40.719586               -74.043117   \n",
      "2      Grove St PATH               40.719586               -74.043117   \n",
      "3       Brunswick St               40.724176               -74.050656   \n",
      "4            Sip Ave               40.730743               -74.063784   \n",
      "\n",
      "   end_station_id end_station_name  end_station_latitude  \\\n",
      "0            3209     Brunswick St             40.724176   \n",
      "1            3213   Van Vorst Park             40.718489   \n",
      "2            3213   Van Vorst Park             40.718489   \n",
      "3            3203    Hamilton Park             40.727596   \n",
      "4            3210   Pershing Field             40.742677   \n",
      "\n",
      "   end_station_longitude  bike_id   user_type  birth_year  gender  \\\n",
      "0             -74.050656    24647  Subscriber      1964.0       2   \n",
      "1             -74.047727    24605  Subscriber      1962.0       1   \n",
      "2             -74.047727    24689  Subscriber      1962.0       2   \n",
      "3             -74.044247    24693  Subscriber      1984.0       1   \n",
      "4             -74.051789    24573    Customer         NaN       0   \n",
      "\n",
      "   duration_exceeded  duration_minutes   age        date  \n",
      "0              False              6.03  52.0  2016-01-01  \n",
      "1              False              3.33  54.0  2016-01-01  \n",
      "2              False              3.37  54.0  2016-01-01  \n",
      "3              False              4.13  32.0  2016-01-01  \n",
      "4              False             15.05   NaN  2016-01-01  \n"
     ]
    }
   ],
   "source": [
    "# getting date only\n",
    "rental_data['date'] = rental_data['start_time'].dt.date\n",
    "print(rental_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "17308dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_duration          start_time           stop_time  start_station_id  \\\n",
      "0            362 2016-01-01 00:02:52 2016-01-01 00:08:54              3186   \n",
      "1            200 2016-01-01 00:18:22 2016-01-01 00:21:42              3186   \n",
      "2            202 2016-01-01 00:18:25 2016-01-01 00:21:47              3186   \n",
      "3            248 2016-01-01 00:23:13 2016-01-01 00:27:21              3209   \n",
      "4            903 2016-01-01 01:03:20 2016-01-01 01:18:24              3195   \n",
      "\n",
      "  start_station_name  start_station_latitude  start_station_longitude  \\\n",
      "0      Grove St PATH               40.719586               -74.043117   \n",
      "1      Grove St PATH               40.719586               -74.043117   \n",
      "2      Grove St PATH               40.719586               -74.043117   \n",
      "3       Brunswick St               40.724176               -74.050656   \n",
      "4            Sip Ave               40.730743               -74.063784   \n",
      "\n",
      "   end_station_id end_station_name  end_station_latitude  ...  birth_year  \\\n",
      "0            3209     Brunswick St             40.724176  ...      1964.0   \n",
      "1            3213   Van Vorst Park             40.718489  ...      1962.0   \n",
      "2            3213   Van Vorst Park             40.718489  ...      1962.0   \n",
      "3            3203    Hamilton Park             40.727596  ...      1984.0   \n",
      "4            3210   Pershing Field             40.742677  ...         NaN   \n",
      "\n",
      "   gender duration_exceeded  duration_minutes   age        date     day  \\\n",
      "0       2             False              6.03  52.0  2016-01-01  Friday   \n",
      "1       1             False              3.33  54.0  2016-01-01  Friday   \n",
      "2       2             False              3.37  54.0  2016-01-01  Friday   \n",
      "3       1             False              4.13  32.0  2016-01-01  Friday   \n",
      "4       0             False             15.05   NaN  2016-01-01  Friday   \n",
      "\n",
      "     month month_id weekend  \n",
      "0  January        1   False  \n",
      "1  January        1   False  \n",
      "2  January        1   False  \n",
      "3  January        1   False  \n",
      "4  January        1   False  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating day of week column\n",
    "rental_data['day'] = rental_data['date'].apply(lambda x: x.strftime('%A'))\n",
    "rental_data['month'] = rental_data['date'].apply(lambda x: x.strftime('%B'))\n",
    "rental_data['month_id'] = rental_data['date'].apply(lambda x: x.month)\n",
    "rental_data['weekend'] = rental_data['day'].apply(lambda x: 1 if (x == 'Saturday' or x == 'Sunday') else 0).astype(bool)\n",
    "print(rental_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c4011",
   "metadata": {},
   "source": [
    "## Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b2661",
   "metadata": {},
   "source": [
    "### Uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "14908c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('newark_airport_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc48b9c",
   "metadata": {},
   "source": [
    "### Examination of weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b11e716b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATION                                         NAME        DATE  \\\n",
      "0  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-01   \n",
      "1  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-02   \n",
      "2  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-03   \n",
      "3  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-04   \n",
      "4  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-05   \n",
      "\n",
      "    AWND  PGTM  PRCP  SNOW  SNWD  TAVG  TMAX  TMIN  TSUN  WDF2   WDF5  WSF2  \\\n",
      "0  12.75   NaN   0.0   0.0   0.0    41    43    34   NaN   270  280.0  25.9   \n",
      "1   9.40   NaN   0.0   0.0   0.0    36    42    30   NaN   260  260.0  21.0   \n",
      "2  10.29   NaN   0.0   0.0   0.0    37    47    28   NaN   270  250.0  23.9   \n",
      "3  17.22   NaN   0.0   0.0   0.0    32    35    14   NaN   330  330.0  25.9   \n",
      "4   9.84   NaN   0.0   0.0   0.0    19    31    10   NaN   360  350.0  25.1   \n",
      "\n",
      "   WSF5  \n",
      "0  35.1  \n",
      "1  25.1  \n",
      "2  30.0  \n",
      "3  33.1  \n",
      "4  31.1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 16 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   STATION  366 non-null    object \n",
      " 1   NAME     366 non-null    object \n",
      " 2   DATE     366 non-null    object \n",
      " 3   AWND     366 non-null    float64\n",
      " 4   PGTM     0 non-null      float64\n",
      " 5   PRCP     366 non-null    float64\n",
      " 6   SNOW     366 non-null    float64\n",
      " 7   SNWD     366 non-null    float64\n",
      " 8   TAVG     366 non-null    int64  \n",
      " 9   TMAX     366 non-null    int64  \n",
      " 10  TMIN     366 non-null    int64  \n",
      " 11  TSUN     0 non-null      float64\n",
      " 12  WDF2     366 non-null    int64  \n",
      " 13  WDF5     364 non-null    float64\n",
      " 14  WSF2     366 non-null    float64\n",
      " 15  WSF5     364 non-null    float64\n",
      "dtypes: float64(9), int64(4), object(3)\n",
      "memory usage: 45.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(weather.head())\n",
    "print(weather.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8dd334",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Column names dont follow the standard convention\n",
    "* Some of the column names have no obvious meaning:\n",
    "    * AWND = average daily wind speed (miles per hour)\n",
    "    * PRCP = precipitation (inches)\n",
    "    * SNOW = Snowfall (inches)\n",
    "    * SNWD = Snow depth (imnches)\n",
    "    * TAVG = Average temperature (Fahrenheit)\n",
    "    * TMAX = Max temp (Fahrenheit)\n",
    "    * TMIN = Min temp (Fahrenheit)\n",
    "    * WDF2 = Direction of fastest 2-second wind - can be removed as dont know when in the day this occured\n",
    "    * WDF5 = Direction of fastest 5-second wind - can be removed as dont know when in the day this occured\n",
    "    * WSF2 = Speed of fastest 2-second wind - can be removed as dont know when in the day this occured\n",
    "    * WSF5 = Speed of fastest 5-second wind - can be removed as dont know when in the day this occured \n",
    "\n",
    "* Station and name are not needed as all the data is from the same location\n",
    "* Date should be in datetime\n",
    "* PGTM and TSUN have no values and can therefore be dropped\n",
    "* There is some missing data in WDF5 and WSF5\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c6f03f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.columns = [x.lower() for x in weather.columns]\n",
    "weather = weather.drop(labels=['station', 'name', 'pgtm', 'tsun', 'wdf2', 'wdf5', 'wsf2', 'wsf5'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8281fcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  average_wind_speed  rainfall  snowfall  snow_depth  tavg  tmax  \\\n",
      "0  2016-01-01               12.75       0.0       0.0         0.0    41    43   \n",
      "1  2016-01-02                9.40       0.0       0.0         0.0    36    42   \n",
      "2  2016-01-03               10.29       0.0       0.0         0.0    37    47   \n",
      "3  2016-01-04               17.22       0.0       0.0         0.0    32    35   \n",
      "4  2016-01-05                9.84       0.0       0.0         0.0    19    31   \n",
      "\n",
      "   tmin  \n",
      "0    34  \n",
      "1    30  \n",
      "2    28  \n",
      "3    14  \n",
      "4    10  \n"
     ]
    }
   ],
   "source": [
    "weather = weather.rename(columns={'awnd':'average_wind_speed', 'prcp':'rainfall', 'snow':'snowfall', 'snwd':'snow_depth'})\n",
    "print(weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "71461f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['date'] = weather['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9fa3839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  average_wind_speed  rainfall  snowfall  snow_depth  tavg  tmax  \\\n",
      "0 2016-01-01               12.75       0.0       0.0         0.0    41    43   \n",
      "1 2016-01-02                9.40       0.0       0.0         0.0    36    42   \n",
      "2 2016-01-03               10.29       0.0       0.0         0.0    37    47   \n",
      "3 2016-01-04               17.22       0.0       0.0         0.0    32    35   \n",
      "4 2016-01-05                9.84       0.0       0.0         0.0    19    31   \n",
      "\n",
      "   tmin  \n",
      "0    34  \n",
      "1    30  \n",
      "2    28  \n",
      "3    14  \n",
      "4    10  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   date                366 non-null    datetime64[ns]\n",
      " 1   average_wind_speed  366 non-null    float64       \n",
      " 2   rainfall            366 non-null    float64       \n",
      " 3   snowfall            366 non-null    float64       \n",
      " 4   snow_depth          366 non-null    float64       \n",
      " 5   tavg                366 non-null    int64         \n",
      " 6   tmax                366 non-null    int64         \n",
      " 7   tmin                366 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3)\n",
      "memory usage: 23.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(weather.head())\n",
    "print(weather.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c70b9a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      date  average_wind_speed    rainfall    snowfall  \\\n",
      "count                  366          366.000000  366.000000  366.000000   \n",
      "mean   2016-07-01 12:00:00            9.429973    0.104945    0.098087   \n",
      "min    2016-01-01 00:00:00            2.460000    0.000000    0.000000   \n",
      "25%    2016-04-01 06:00:00            6.765000    0.000000    0.000000   \n",
      "50%    2016-07-01 12:00:00            8.720000    0.000000    0.000000   \n",
      "75%    2016-09-30 18:00:00           11.410000    0.030000    0.000000   \n",
      "max    2016-12-31 00:00:00           22.820000    2.790000   24.000000   \n",
      "std                    NaN            3.748174    0.307496    1.276498   \n",
      "\n",
      "       snow_depth        tavg        tmax        tmin  \n",
      "count  366.000000  366.000000  366.000000  366.000000  \n",
      "mean     0.342623   57.196721   65.991803   48.459016  \n",
      "min      0.000000    8.000000   18.000000    0.000000  \n",
      "25%      0.000000   43.000000   51.250000   35.000000  \n",
      "50%      0.000000   56.000000   66.000000   47.000000  \n",
      "75%      0.000000   74.000000   83.000000   64.000000  \n",
      "max     20.100000   89.000000   99.000000   80.000000  \n",
      "std      2.078510   17.466981   18.606301   17.135790  \n"
     ]
    }
   ],
   "source": [
    "print(weather.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df6224",
   "metadata": {},
   "source": [
    "* All of the data now looks reliable. It would also be helpful to have boolean columns for rain and snow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5048c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['rain'] = weather['rainfall'].apply(lambda x: 1 if x > 0 else 0).astype(bool)\n",
    "weather['snow'] = weather['snowfall'].apply(lambda x: 1 if x > 0 else 0).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "18fddb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  average_wind_speed  rainfall  snowfall  snow_depth  tavg  tmax  \\\n",
      "0 2016-01-01               12.75       0.0       0.0         0.0    41    43   \n",
      "1 2016-01-02                9.40       0.0       0.0         0.0    36    42   \n",
      "2 2016-01-03               10.29       0.0       0.0         0.0    37    47   \n",
      "3 2016-01-04               17.22       0.0       0.0         0.0    32    35   \n",
      "4 2016-01-05                9.84       0.0       0.0         0.0    19    31   \n",
      "\n",
      "   tmin   rain   snow  \n",
      "0    34  False  False  \n",
      "1    30  False  False  \n",
      "2    28  False  False  \n",
      "3    14  False  False  \n",
      "4    10  False  False  \n"
     ]
    }
   ],
   "source": [
    "print(weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1e8f99ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_duration          start_time           stop_time  start_station_id  \\\n",
      "0            362 2016-01-01 00:02:52 2016-01-01 00:08:54              3186   \n",
      "1            200 2016-01-01 00:18:22 2016-01-01 00:21:42              3186   \n",
      "2            202 2016-01-01 00:18:25 2016-01-01 00:21:47              3186   \n",
      "3            248 2016-01-01 00:23:13 2016-01-01 00:27:21              3209   \n",
      "4            903 2016-01-01 01:03:20 2016-01-01 01:18:24              3195   \n",
      "\n",
      "  start_station_name  start_station_latitude  start_station_longitude  \\\n",
      "0      Grove St PATH               40.719586               -74.043117   \n",
      "1      Grove St PATH               40.719586               -74.043117   \n",
      "2      Grove St PATH               40.719586               -74.043117   \n",
      "3       Brunswick St               40.724176               -74.050656   \n",
      "4            Sip Ave               40.730743               -74.063784   \n",
      "\n",
      "   end_station_id end_station_name  end_station_latitude  ...  birth_year  \\\n",
      "0            3209     Brunswick St             40.724176  ...      1964.0   \n",
      "1            3213   Van Vorst Park             40.718489  ...      1962.0   \n",
      "2            3213   Van Vorst Park             40.718489  ...      1962.0   \n",
      "3            3203    Hamilton Park             40.727596  ...      1984.0   \n",
      "4            3210   Pershing Field             40.742677  ...         NaN   \n",
      "\n",
      "   gender duration_exceeded  duration_minutes   age        date     day  \\\n",
      "0       2             False              6.03  52.0  2016-01-01  Friday   \n",
      "1       1             False              3.33  54.0  2016-01-01  Friday   \n",
      "2       2             False              3.37  54.0  2016-01-01  Friday   \n",
      "3       1             False              4.13  32.0  2016-01-01  Friday   \n",
      "4       0             False             15.05   NaN  2016-01-01  Friday   \n",
      "\n",
      "     month month_id weekend  \n",
      "0  January        1   False  \n",
      "1  January        1   False  \n",
      "2  January        1   False  \n",
      "3  January        1   False  \n",
      "4  January        1   False  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "        date  average_wind_speed  rainfall  snowfall  snow_depth  tavg  tmax  \\\n",
      "0 2016-01-01               12.75       0.0       0.0         0.0    41    43   \n",
      "1 2016-01-02                9.40       0.0       0.0         0.0    36    42   \n",
      "2 2016-01-03               10.29       0.0       0.0         0.0    37    47   \n",
      "3 2016-01-04               17.22       0.0       0.0         0.0    32    35   \n",
      "4 2016-01-05                9.84       0.0       0.0         0.0    19    31   \n",
      "\n",
      "   tmin   rain   snow  \n",
      "0    34  False  False  \n",
      "1    30  False  False  \n",
      "2    28  False  False  \n",
      "3    14  False  False  \n",
      "4    10  False  False  \n"
     ]
    }
   ],
   "source": [
    "print(rental_data.head())\n",
    "print(weather.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20ca33",
   "metadata": {},
   "source": [
    "## Dataframes for SQL tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5501b",
   "metadata": {},
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cc993d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date   rain   snow  tavg  average_wind_speed\n",
      "0 2016-01-01  False  False    41               12.75\n",
      "1 2016-01-02  False  False    36                9.40\n",
      "2 2016-01-03  False  False    37               10.29\n",
      "3 2016-01-04  False  False    32               17.22\n",
      "4 2016-01-05  False  False    19                9.84\n"
     ]
    }
   ],
   "source": [
    "weather_sql = weather[['date', 'rain', 'snow', 'tavg', 'average_wind_speed']]\n",
    "print(weather_sql.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a95f37",
   "metadata": {},
   "source": [
    "### Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "df9a621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data for start and end stations\n",
    "start_station = rental_data[['start_station_id', 'start_station_name', 'start_station_latitude', 'start_station_longitude']]\n",
    "end_station = rental_data[['end_station_id', 'end_station_name', 'end_station_latitude', 'end_station_longitude']]\n",
    "\n",
    "# rename columns so that they match for start and end stations\n",
    "start_station.columns = ['station_id', 'station_name', 'station_latitude', 'station_longitude']\n",
    "end_station.columns = ['station_id', 'station_name', 'station_latitude', 'station_longitude']\n",
    "\n",
    "# merge data into one table for all stations and drop duplicates\n",
    "station_sql = pd.concat([start_station, end_station])\n",
    "station_sql = station_sql.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6f96fc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station_id   station_name  station_latitude  station_longitude\n",
      "0        3186  Grove St PATH         40.719586         -74.043117\n",
      "1        3186  Grove St PATH         40.719586         -74.043117\n",
      "2        3186  Grove St PATH         40.719586         -74.043117\n",
      "3        3209   Brunswick St         40.724176         -74.050656\n",
      "4        3195        Sip Ave         40.730743         -74.063784\n",
      "   station_id    station_name  station_latitude  station_longitude\n",
      "0        3209    Brunswick St         40.724176         -74.050656\n",
      "1        3213  Van Vorst Park         40.718489         -74.047727\n",
      "2        3213  Van Vorst Park         40.718489         -74.047727\n",
      "3        3203   Hamilton Park         40.727596         -74.044247\n",
      "4        3210  Pershing Field         40.742677         -74.051789\n",
      "   station_id   station_name  station_latitude  station_longitude\n",
      "0        3186  Grove St PATH         40.719586         -74.043117\n",
      "1        3209   Brunswick St         40.724176         -74.050656\n",
      "2        3195        Sip Ave         40.730743         -74.063784\n",
      "3        3211     Newark Ave         40.721525         -74.046305\n",
      "4        3187      Warren St         40.721124         -74.038051\n"
     ]
    }
   ],
   "source": [
    "print(start_station.head())\n",
    "print(end_station.head())\n",
    "print(station_sql.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b09fd7",
   "metadata": {},
   "source": [
    "### Rider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5c7082c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate rider info\n",
    "rider_sql = rental_data[['user_type', 'birth_year', 'gender', 'age']]\n",
    "# remove any duplicates\n",
    "rider_sql = rider_sql.drop_duplicates().reset_index(drop=True)\n",
    "# set up user_id\n",
    "rider_sql['user_id'] = rider_sql.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "efad6ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_type  birth_year  gender   age  user_id\n",
      "0  Subscriber      1964.0       2  52.0        0\n",
      "1  Subscriber      1962.0       1  54.0        1\n",
      "2  Subscriber      1962.0       2  54.0        2\n",
      "3  Subscriber      1984.0       1  32.0        3\n",
      "4    Customer         NaN       0   NaN        4\n"
     ]
    }
   ],
   "source": [
    "print(rider_sql.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae27965",
   "metadata": {},
   "source": [
    "### Journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "600770b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_duration          start_time           stop_time  start_station_id  \\\n",
      "0            362 2016-01-01 00:02:52 2016-01-01 00:08:54              3186   \n",
      "1            452 2016-01-03 16:25:48 2016-01-03 16:33:21              3209   \n",
      "2            227 2016-01-03 17:11:56 2016-01-03 17:15:43              3211   \n",
      "3            263 2016-01-03 18:18:14 2016-01-03 18:22:38              3203   \n",
      "4            497 2016-01-03 22:11:25 2016-01-03 22:19:43              3186   \n",
      "\n",
      "   end_station_id  bike_id  duration_exceeded  duration_minutes        date  \\\n",
      "0            3209    24647              False              6.03  2016-01-01   \n",
      "1            3185    24662              False              7.53  2016-01-03   \n",
      "2            3203    24633              False              3.78  2016-01-03   \n",
      "3            3211    24633              False              4.38  2016-01-03   \n",
      "4            3209    24597              False              8.28  2016-01-03   \n",
      "\n",
      "   month_id  user_id     date_id  journey_id  \n",
      "0         1        0  2016-01-01           0  \n",
      "1         1        0  2016-01-03           1  \n",
      "2         1        0  2016-01-03           2  \n",
      "3         1        0  2016-01-03           3  \n",
      "4         1        0  2016-01-03           4  \n"
     ]
    }
   ],
   "source": [
    "combined_journey_rider = rental_data.merge(rider_sql, on=['user_type', 'birth_year', 'gender', 'age'])\n",
    "journey_sql = combined_journey_rider.drop(['user_type','birth_year','gender','age', 'day', 'month', 'weekend', 'start_station_name', 'start_station_latitude', 'start_station_longitude', 'end_station_name', 'end_station_latitude', 'end_station_longitude'], axis=1)\n",
    "journey_sql['date_id'] = journey_sql['date']\n",
    "journey_sql['journey_id'] = journey_sql.index\n",
    "print(journey_sql.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133d90e",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c496c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date       day    month  month_id  weekend\n",
      "0  2016-01-01    Friday  January         1    False\n",
      "1  2016-01-02  Saturday  January         1     True\n",
      "2  2016-01-03    Sunday  January         1     True\n",
      "3  2016-01-04    Monday  January         1    False\n",
      "4  2016-01-05   Tuesday  January         1    False\n"
     ]
    }
   ],
   "source": [
    "date_sql = rental_data[['date', 'day', 'month', 'month_id', 'weekend']]\n",
    "date_sql = date_sql.drop_duplicates().reset_index(drop=True)\n",
    "print(date_sql.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34983650",
   "metadata": {},
   "source": [
    "## Connect to Postgresql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f17b4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://postgres:postgres@localhost:5432/bike_rentals')\n",
    "\n",
    "con = engine.connect()\n",
    "journey_sql.to_sql('journey', con, if_exists='replace',index=False,chunksize=10000)\n",
    "weather_sql.to_sql('weather', con, if_exists='replace',index=False,chunksize=10000)\n",
    "station_sql.to_sql('station', con, if_exists='replace',index=False,chunksize=10000)\n",
    "rider_sql.to_sql('rider', con, if_exists='replace',index=False,chunksize=10000)\n",
    "date_sql.to_sql('date', con, if_exists='replace',index=False,chunksize=10000)\n",
    "con.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b8cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
